{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=fetch_openml(\"mnist_784\",version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=mnist.data,mnist.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "idx_al=np.random.randint(0,X.shape[0],size=30)\n",
    "\n",
    "for i in range(len(idx_al)):\n",
    "    x_val=X[idx_al[i],:].reshape(28,28)\n",
    "    y_val=y[idx_al[i]]\n",
    "    plt.subplot(5,6,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_val,cmap=plt.cm.Greys_r)\n",
    "    plt.title(\"Digito\"+str(int(y_val)),fontsize=15,fontweight=\"bold\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=np.where(ytrain%2==0,1,0)\n",
    "ytest=np.where(ytest%2==0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score,accuracy_score,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determinando o melhor limiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log.predict_proba(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_1=reg_log.predict_proba(xtrain)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limiar=np.linspace(0.05,0.95,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "for i in limiar:\n",
    "    pred_i=np.where(prob_1>i,1,0)\n",
    "    precision.append(precision_score(ytrain,pred_i))\n",
    "    recall.append(recall_score(ytrain,pred_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(range(len(limiar)),precision,c=\"red\",lw=2,label=\"Curva Precision\")\n",
    "plt.plot(range(len(limiar)),precision,c=\"red\",lw=4,alpha=0.8)\n",
    "plt.plot(range(len(limiar)),recall,c=\"blue\",lw=2,label=\"Curva Recall\")\n",
    "plt.xticks(range(len(limiar)), limiar.round(2), fontsize = 8)\n",
    "plt.title(\"Precision X Recall\",fontsize=16)\n",
    "plt.legend(fontsize=15,bbox_to_anchor=[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Com as curvas plotadas podemos definir que o melhor limiar para nosso estudo será o 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciaremos a plotagem da curva ROC e da AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rltrain_pred=rl.predict_proba(xtrain)[:,1]\n",
    "rlteste_pred=rl.predict_proba(xtest)[:,1]\n",
    "\n",
    "fpr,vpr,the=roc_curve(ytrain,rltrain_pred)\n",
    "fpr1,vpr1,the1=roc_curve(ytest,rlteste_pred)\n",
    "\n",
    "plt.figure(figsize=[16,6])\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr,vpr,c=\"red\")\n",
    "plt.title(\"Curva ROC de treino \",fontsize=14)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fpr1,vpr1,c=\"blue\")\n",
    "plt.title(\"Curva ROC de teste\",fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"A AUC para dados de treino foi de: \", roc_auc_score(ytrain,rltrain_pred))\n",
    "\n",
    "print(\"A AUC para dados de teste foi de: \", roc_auc_score(ytest,rlteste_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knntrain_pred=knn.predict_proba(xtrain)[:,1]\n",
    "knnteste_pred=knn.predict_proba(xtest)[:,1]\n",
    "\n",
    "fpr,vpr,the=roc_curve(ytrain,knntrain_pred)\n",
    "fpr1,vpr1,the1=roc_curve(ytest,knnteste_pred)\n",
    "\n",
    "plt.figure(figsize=[16,6])\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr,vpr,c=\"red\")\n",
    "plt.title(\"Curva ROC de treino \",fontsize=14)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fpr1,vpr1,c=\"blue\")\n",
    "plt.title(\"Curva ROC de teste\",fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"A AUC para dados de treino foi de: \", roc_auc_score(ytrain,knntrain_pred))\n",
    "\n",
    "print(\"A AUC para dados de teste foi de: \", roc_auc_score(ytest,knnteste_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução da validação cruzada manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao_cruzada_manual(classificador,x,y,num_folds,metrica):\n",
    "    kf=KFold(n_splits=num_folds)\n",
    "    metrica_train=[]\n",
    "    metrica_test=[]\n",
    "    plt.figure(figsize=[20,15])\n",
    "    for train_idx,test_idx in kf.split(x,y):\n",
    "        xtrain_folds=x[train_idx]\n",
    "        ytrain_folds=y[train_idx]\n",
    "        xtest_folds=x[test_idx]\n",
    "        ytest_folds=y[test_idx]\n",
    "        \n",
    "        reg=classificador.fit(xtrain_folds,ytrain_folds)\n",
    "        pred_train=reg.predict(xtrain_folds)\n",
    "        pred_test=reg.predict(xtest_folds)\n",
    "        metrica_train.append(metrica(ytrain_folds,pred_train))\n",
    "        metrica_test.append(metrica(ytest_folds,pred_test))\n",
    "    print(\"A média da métrica solicitada nos dados de treino foi de:   \",np.mean(metrica_train))    \n",
    "    print(\"A média da métrica solicitada nos dados de teste foi de:   \",np.mean(metrica_test))\n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao_cruzada_manual(LogisticRegression(),xtrain,ytrain,5,f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
